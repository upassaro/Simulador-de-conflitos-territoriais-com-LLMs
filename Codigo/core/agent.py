import json

from langchain.memory import VectorStoreRetrieverMemory
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import Runnable, RunnablePassthrough
from langchain_huggingface import HuggingFaceEmbeddings
from pydantic import ValidationError

# Importa todos os modelos de dados e o nosso erro personalizado
from .models import Decision, DecisionValidationError, FinalResolution

# --- PROMPT PARA A DECIS√ÉO DA RODADA ---
AGENT_PROMPT = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """Voc√™ √© o principal tomador de decis√µes estrat√©gicas do Estado-Na√ß√£o fict√≠cio: {actor_name}.
Sua resposta DEVE ser um √∫nico e v√°lido objeto JSON, estritamente conforme o schema fornecido.
Aten√ß√£o: Garanta que a sua sa√≠da JSON usa a codifica√ß√£o UTF-8 correta para todos os caracteres especiais (ex: '√ß', '√£').
N√£o adicione nenhum texto ou coment√°rio fora do JSON.""",
        ),
        (
            "user",
            """# SEUS OBJETIVOS ESTRAT√âGICOS PRINCIPAIS:
{objectives}

# CONTEXTO GLOBAL E DO SEU ESTADO
- **Cen√°rio Atual:** {synopsis}
- **Seu Papel Neste Cen√°rio:** {actor_role}
- **Seu Perfil Ideol√≥gico:** {ideological_profile}
- **Contexto Hist√≥rico do seu Estado:** {historical_context}
- **Situa√ß√£o Interna Atual:** {internal_context}
- **Suas Capacidades Militares e Tecnol√≥gicas:** {capabilities}
- **Suas Linhas Vermelhas (n√£o cruzar):** {red_lines}

# MEM√ìRIAS RELEVANTES DE A√á√ïES PASSADAS (Recuperadas para si):
{history}

# BRIEFING DE INTELIG√äNCIA DA √öLTIMA RODADA
- **Eventos:** {situation_summary}
- **An√°lise de Impacto:** {impact_analysis}
- **N√≠vel de Escalada Atual:** N√≠vel {escalation_level} (de 0 a 5).

# SITUA√á√ÉO ATUAL
- **Rodada Atual:** {round_number} de 20

# SUA MISS√ÉO
- Sua a√ß√£o na √∫ltima rodada foi: '{last_action}'. Repetir a mesma estrat√©gia pode ser ineficaz.
- Avalie se a sua pr√≥xima a√ß√£o o aproxima dos seus OBJETIVOS ESTRAT√âGICOS.

Com base em TODO o contexto, decida a pr√≥xima a√ß√£o estrat√©gica do seu Estado.
1.  **Escolha UMA A√ß√£o Principal (`action_primary`):** ...
2.  **Justifique sua Decis√£o (`justification_text`):** ...
3.  **Decida sobre o Conselho Global:** ...

# REGRAS R√çGIDAS PARA A SA√çDA:
- Voc√™ DEVE escolher os valores para os campos 'action_primary' e 'council_action' COPIANDO EXATAMENTE as strings da lista de op√ß√µes fornecida no schema JSON abaixo.
- N√ÉO modifique, abrevie ou reescreva as op√ß√µes. A sua resposta deve ser uma correspond√™ncia exata.

# SCHEMA JSON OBRIGAT√ìRIO
{schema}
""",
        ),
    ]
)

CORRECTION_PROMPT = ChatPromptTemplate.from_template(
    """Sua tarefa √© corrigir um objeto JSON inv√°lido. Um agente de IA tentou gerar uma resposta JSON, mas falhou na valida√ß√£o.

# SCHEMA JSON OBRIGAT√ìRIO (A RESPOSTA DEVE SEGUIR ESTA ESTRUTURA):
{schema}

# ERRO DE VALIDA√á√ÉO DETECTADO:
{validation_error}

# SA√çDA JSON DEFEITUOSA (GERADA PELO AGENTE):
```json
{faulty_output}

SUA MISS√ÉO:
Analise o erro, a sa√≠da defeituosa e o schema. Corrija o JSON para que ele se conforme estritamente com o schema e o erro apontado.
Sua resposta deve conter APENAS o objeto JSON corrigido e v√°lido, sem nenhum outro texto, coment√°rio ou explica√ß√£o.
"""
)

class StateAgent:
    """Representa um √∫nico ator com mem√≥ria vetorial e capacidade de autocorre√ß√£o."""
    def __init__(
    self, llm: Runnable, actor_data: dict, role: str, embedding_model: HuggingFaceEmbeddings
    ):
        """
        Inicializa o agente de estado.

        Args:
            llm (Runnable): O modelo de linguagem a ser usado.
            actor_data (dict): Dados que definem o ator.
            role (str): O papel do ator no cen√°rio.
            embedding_model (HuggingFaceEmbeddings): O modelo para criar embeddings de texto.
        """
        self.llm = llm
        self.actor_data = actor_data
        self.name = actor_data.get("name", "Nome Desconhecido")
        self.role = role
        self.llm_config = {}

        # Tenta extrair a configura√ß√£o do objeto LLM para uso posterior
        if hasattr(llm, "bound") and hasattr(llm.bound, "model"):
            self.llm_config = {"provider": "desconhecido", "model": llm.bound.model}
        elif hasattr(llm, "model_name"):
            self.llm_config = {"provider": "desconhecido", "model": llm.model_name}

        # Configura a mem√≥ria vetorial para o agente
        vectorstore = FAISS.from_texts(
            texts=["In√≠cio do registo de mem√≥ria."], embedding=embedding_model
        )
        retriever = vectorstore.as_retriever(search_kwargs=dict(k=3))

        self.memory = VectorStoreRetrieverMemory(
            retriever=retriever,
            input_key="situation_summary",
            memory_key="history",
        )

    def decide(
        self,
        synopsis: str,
        situation_summary: str,
        round_number: int,
        last_action: str | None,
        impact_analysis: str,
        escalation_level: int,
    ) -> Decision:
        """
        Processa o contexto e invoca o LLM para decidir, com um loop de autocorre√ß√£o.

        Args:
            synopsis (str): Sinopse geral do cen√°rio.
            situation_summary (str): Resumo dos eventos da √∫ltima rodada.
            round_number (int): O n√∫mero da rodada atual.
            last_action (str | None): A √∫ltima a√ß√£o tomada por este agente.
            impact_analysis (str): An√°lise do impacto da √∫ltima rodada.
            escalation_level (int): O n√≠vel de escalada atual.

        Returns:
            Decision: Um objeto de decis√£o validado.

        Raises:
            DecisionValidationError: Se o agente n√£o conseguir produzir uma sa√≠da v√°lida.
        """
        print(f"\nü§ñ Invocando agente: {self.name} (Papel: {self.role})")

        max_attempts = 2
        response_data = None

        for attempt in range(max_attempts):
            try:
                # Na primeira tentativa, usa o prompt normal
                if attempt == 0:
                    chain = (
                        RunnablePassthrough.assign(
                            history=self.memory.load_memory_variables
                        )
                        | AGENT_PROMPT
                        | self.llm
                    )

                    objectives = self.actor_data.get(
                        "objectives", "Agir conforme o perfil ideol√≥gico."
                    )
                    red_lines = self.actor_data.get("alliances", {}).get(
                        "red_lines", "Nenhuma definida."
                    )

                    response_data = chain.invoke(
                        {
                            "objectives": objectives,
                            "actor_name": self.name,
                            "synopsis": synopsis,
                            "actor_role": self.role,
                            "ideological_profile": self.actor_data.get("ideological_profile"),
                            "historical_context": json.dumps(self.actor_data.get("historical_context", {})),
                            "internal_context": json.dumps(self.actor_data.get("internal_context", {})),
                            "capabilities": json.dumps(self.actor_data.get("capabilities", {})),
                            "red_lines": red_lines,
                            "round_number": round_number,
                            "situation_summary": situation_summary or "Nenhuma a√ß√£o foi tomada ainda.",
                            "last_action": last_action or "Nenhuma (esta √© a primeira rodada)",
                            "impact_analysis": impact_analysis,
                            "escalation_level": escalation_level,
                            "schema": json.dumps(Decision.model_json_schema(), ensure_ascii=False, indent=2),
                        }
                    )

                # Valida a resposta com o modelo Pydantic
                decision = (
                    Decision(**response_data)
                    if isinstance(response_data, dict)
                    else Decision.model_validate(response_data)
                )

                # Salva a decis√£o na mem√≥ria
                memoria_para_guardar = (
                    f"Na rodada {round_number}, meus objetivos eram '{objectives}'. "
                    f"A situa√ß√£o era: '{situation_summary}'. "
                    f"Minha decis√£o foi '{decision.action_primary}' porque '{decision.justification_text}'."
                )
                self.memory.save_context(
                    {"situation_summary": situation_summary or "In√≠cio da simula√ß√£o."},
                    {"output": memoria_para_guardar},
                )
                print(f"  -> Mem√≥ria de '{self.name}' foi atualizada.")
                return decision

            except ValidationError as e:
                print(f"   ‚ö†Ô∏è Erro de valida√ß√£o Pydantic para '{self.name}' na tentativa {attempt + 1}.")

                if attempt < max_attempts - 1:
                    print("      A tentar autocorre√ß√£o...")
                    correction_chain = CORRECTION_PROMPT | self.llm

                    faulty_output_str = (
                        json.dumps(response_data, ensure_ascii=False)
                        if isinstance(response_data, dict)
                        else str(response_data)
                    )

                    # Usa a sa√≠da defeituosa para tentar a corre√ß√£o
                    response_data = correction_chain.invoke(
                        {
                            "validation_error": str(e),
                            "faulty_output": faulty_output_str,
                            "schema": json.dumps(Decision.model_json_schema(), ensure_ascii=False, indent=2),
                        }
                    )
                else:
                    print(f"   ‚ùå Autocorre√ß√£o falhou para '{self.name}'. A registar a falha definitiva.")
                    raise DecisionValidationError(message=str(e), raw_output=response_data)

        raise DecisionValidationError(
            message="O agente n√£o conseguiu produzir uma decis√£o v√°lida ap√≥s as tentativas de corre√ß√£o.",
            raw_output=response_data,
        )