ğŸŒ SimulaÃ§Ã£o de RelaÃ§Ãµes Internacionais com Agentes Cognitivos (LLMs)

Este repositÃ³rio contÃ©m um framework de simulaÃ§Ã£o multi-agente projetado para modelar cenÃ¡rios de crise geopolÃ­tica e tomada de decisÃ£o estratÃ©gica. O sistema utiliza Grandes Modelos de Linguagem (LLMs) para personificar Chefes de Estado, um Analista de InteligÃªncia e um Juiz AcadÃªmico, integrando conceitos de Teoria das RelaÃ§Ãµes Internacionais com engenharia de prompt avanÃ§ada.

ğŸš€ VisÃ£o Geral

O projeto orquestra uma simulaÃ§Ã£o baseada em turnos onde diferentes Estados-NaÃ§Ã£o (agentes) interagem diante de um cenÃ¡rio de crise. Diferente de chatbots comuns, este sistema implementa:

    Agentes de Estado: Atores com memÃ³ria persistente (RAG), perfil ideolÃ³gico, objetivos estratÃ©gicos e "linhas vermelhas".

    Juiz Especialista (RAG): Um agente avaliador que consulta uma base de conhecimento vetorial (um manual acadÃªmico de RI) para classificar as aÃ§Ãµes dos jogadores conforme teorias clÃ¡ssicas (Neorrealismo, Neoliberalismo, Construtivismo).

    Analista de Impacto: Um mÃ³dulo que resume as consequÃªncias de cada rodada e determina o nÃ­vel de escalada do conflito (DEFCON/Escalada).

    SaÃ­da Estruturada: Uso rigoroso de Pydantic para garantir que as decisÃµes dos LLMs sigam schemas JSON validados e aÃ§Ãµes prÃ©-definidas.

ğŸ› ï¸ Arquitetura TÃ©cnica

O sistema Ã© construÃ­do em Python utilizando o ecossistema LangChain.

    Orquestrador (main.py): Gerencia o loop de simulaÃ§Ã£o, carregamento de cenÃ¡rios e persistÃªncia de dados (CSV).

    Core (core/):

        agent.py: Implementa a memÃ³ria vetorial (FAISS) e o loop de decisÃ£o com autocorreÃ§Ã£o (retry parser) para garantir JSONs vÃ¡lidos.

        judge.py: Pipeline RAG que fragmenta o manual de RI (manual_ri.pdf), cria embeddings e avalia a coerÃªncia teÃ³rica das jogadas.

        llm_builder.py: Factory para instanciar modelos de mÃºltiplos provedores (OpenAI, Groq/Llama, DeepSeek, Maritaca, xAI).

    ConfiguraÃ§Ã£o: Sistema modular para definir quais modelos controlam quais agentes.

ğŸ“‹ PrÃ©-requisitos

    Python 3.10+

    Bibliotecas listadas em requirements.txt

    Chaves de API para os provedores que deseja utilizar (OpenAI, Groq, etc.)

âš™ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

    Clone o repositÃ³rio:
    Bash

git clone https://github.com/upassaro/Simulador-de-conflitos-territoriais-com-LLMs
cd seu-projeto

Instale as dependÃªncias: Recomenda-se o uso de um ambiente virtual (venv).
Bash

pip install -r requirements.txt

Configure as VariÃ¡veis de Ambiente: Crie um arquivo .env na raiz do projeto e adicione suas chaves de API:
Snippet de cÃ³digo

    OPENAI_API_KEY=sk-...
    GROQ_API_KEY=gsk_...
    MARITACA_API_KEY=...
    DEEPSEEK_API_KEY=...
    # Adicione apenas as chaves dos modelos que pretende usar

    Arquivos de Dados NecessÃ¡rios: Certifique-se de que a pasta data/ contenha:

        cenarios.json: Arquivo com a definiÃ§Ã£o dos atores, contexto e sinopse da crise.

        manual_ri.pdf: O livro-texto ou artigo acadÃªmico que servirÃ¡ de base para o Juiz (RAG).

â–¶ï¸ Como Executar

Para iniciar a simulaÃ§Ã£o completa (executando todos os cenÃ¡rios definidos em data/cenarios.json):
Bash

python main.py

O sistema verificarÃ¡ se o cenÃ¡rio jÃ¡ foi simulado. Caso contrÃ¡rio, iniciarÃ¡ as rodadas, exibindo no console as decisÃµes dos agentes, os vereditos do juiz e a anÃ¡lise de impacto.

ğŸ“‚ Estrutura do Projeto

Plaintext

.
â”œâ”€â”€ config/
â”‚   â””â”€â”€ llm_config.py      # Mapeamento de modelos (GPT-4, Llama-3, etc.)
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ agent.py           # LÃ³gica do Agente de Estado (MemÃ³ria + DecisÃ£o)
â”‚   â”œâ”€â”€ analysis.py        # Agente Analista de InteligÃªncia
â”‚   â”œâ”€â”€ judge.py           # Agente Juiz (RAG + AvaliaÃ§Ã£o TeÃ³rica)
â”‚   â”œâ”€â”€ llm_builder.py     # Construtor de LLMs e Parsers
â”‚   â””â”€â”€ models.py          # Schemas Pydantic (Decision, Verdict)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cenarios.json      # DefiniÃ§Ã£o dos cenÃ¡rios de simulaÃ§Ã£o
â”‚   â””â”€â”€ manual_ri.pdf      # Base de conhecimento para o Juiz
â”œâ”€â”€ outputs/               # Resultados gerados (CSV)
â”œâ”€â”€ main.py                # Entry point da aplicaÃ§Ã£o
â”œâ”€â”€ requirements.txt       # DependÃªncias do projeto
â””â”€â”€ .env                   # VariÃ¡veis de ambiente (nÃ£o versionado)

ğŸ§ª Modelos Suportados

A arquitetura Ã© agnÃ³stica ao modelo, suportando atualmente via llm_config.py:

    OpenAI: GPT-4o, GPT-5-mini (simulado/beta)

    Groq: Llama 3 (70B)

    DeepSeek: DeepSeek-V3/Reasoner

    Maritaca AI: SabiÃ¡-3

    xAI: Grok

ğŸ“Š Resultados

Os resultados de cada simulaÃ§Ã£o sÃ£o salvos automaticamente na pasta outputs/ em formato CSV, contendo:

    Rodada e Timestamp

    AÃ§Ã£o escolhida e justificativa

    ParticipaÃ§Ã£o e voto no Conselho Global

    Veredito do Juiz (Realismo/Liberalismo/Construtivismo) e racional

    Modelo de LLM utilizado pelo agente

ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Consulte o arquivo LICENSE para mais detalhes.
